---
permalink: /
title: "\"In the middle of difficulty lies opportunity.\" _--Albert Einstein_"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About me

Welcome to my academic page! My Chinese name is Wei Shen (沈蔚), I am excited to share my journey and research endeavors in the field of artificial intelligence. Now I am a research scientist in Baichuan Inc. with special focus on improving the cabability of Baichuan-series LLMs with [Dong Yan](https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=lvztRUkAAAAJ).

I completed my bachelor's degree at Huazhong University of Science and Technology (HUST) in 2020. And I competed my master's degree at Fudan University, working in the NLP Lab under the guidance of [Xuanjing Huang](https://xuanjing-huang.github.io/) as my advisor, with [Qi Zhang](http://qizhang.info/)  as my co-advisor.

I am passionate about leveraging language models to enhance various aspects of AI and contribute to the development of advanced and responsible AI systems. 

## Research Interests
My research interests primarily revolve around Natural Language Processing (NLP), with a specific focus on LLM alignment, including reward modeling, RL. Additionally, I am eager to explore the realm of LLM agents and contribute to advancements in that area.

## Education
* M.Eng. in Fudan University, NLP Lab, 2021-2024, Shanghai
  <!-- * advisor: [Xuanjing Huang](https://scholar.google.com/citations?user=AnBUn0QAAAAJ&hl=en), and co-advisor [Qi Zhang](http://qizhang.info/) and [Tao Gui](https://guitaowufeng.github.io/) -->
* B.Eng. in Huazhong University of Science and Technology, 2016-2020, Wuhan
* High School in Changjun High School, 2013-2016, Changsha

## Experience
* 2024.5 - present: Research Scientist
  * Baichuan Inc, RL team
  * Leader: [Dong Yan](https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=lvztRUkAAAAJ)
       
* 2023.8 - 2024.4: Research Internship
  * ByteDance AI Lab, Responsible AI team
  * Supervisor: [Liu Yang](http://www.yliuu.com/), Xiaoying Zhang
 
* 2021.9 - 2022.3: Research Internship
  * Fudan CISL Lab
  * Supervisor: [Shang Li](https://scholar.google.com/citations?user=AnBUn0QAAAAJ&hl=en)
      
## News
[2024.5.22] I am proud to announce my joining Baichuan Inc. as a Research Scientist!

[2024.1.16] Our paper "Improving Generalization of Alignment with Human Preferences through Group Invariant Learning" has been accepted for **spotlight**(5%) on ICLR 2024!

[2023.12.15] Our paper "Delve into PPO: Implementation Matters for Stable RLHF" has won the Best Paper on Instruction Workshop @ NeurIPS 2023!

## Projects
<img src="../images/moss_logo.png" width="200">

[MOSS-RLHF](https://openlmlab.github.io/MOSS-RLHF/) (An open-source RLHF project aims to help LLMs to achieve alignment easily)


## Publications
## 2024 ##

**Linear Alignment: A Closed-form Solution for Aligning Human Preferences without Tuning and Feedback (ICML 2024)**

* _Songyang Gao&#9733;, Qiming Ge&#9733;, **Wei Shen**, Shihan Dou, Junjie Ye, Xiao Wang, Rui Zheng, Yicheng Zou, Zhi Chen, Hang Yan, Qi Zhang, Dahua Lin_

**Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning (ICML 2024)**

* _Zhiheng Xi&#9733;, Wenxiang Chen&#9733;, Boyang Hong&#9733;, Senjie Jin&#9733;, Rui Zheng, Wei He, Yiwen Ding, Shichun Liu, Xin Guo, Junzhe Wang, Honglin Guo, **Wei Shen**, Xiaoran Fan, Yuhao Zhou, Shihan Dou, Xiao Wang, Xinbo Zhang, Peng Sun, Tao Gui, Qi Zhang, Xuanjing Huang_

**LoRAMoE: Revolutionizing Mixture of Experts for Maintaining World Knowledge in Language Model Alignment (ACL 2024)**

* _Shihan Dou&#9733;, Enyu Zhou&#9733;, Yan Liu, Songyang Gao, Jun Zhao, **Wei Shen**, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Xiaoran Fan, Shiliang Pu, Jiang Zhu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang_


**Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards (Preprint)**

* _**Wei Shen**&#9733;, Xiaoying Zhang&#9733;, Yuanshun Yao, Rui Zheng, Hongyi Guo, Yang Liu_


**Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation (Preprint)**

* _Xiaoying Zhang&#9733;, Jean-Francois Ton&#9733;, **Wei Shen**, Hongning Wang, Yang Liu_

**Secrets of RLHF in Large Language Models Part II: Reward Modeling (Preprint)**

* _Binghai Wang&#9733;, Rui Zheng&#9733;, Lu Chen&#9733;, Yan Liu, Shihan Dou, Caishuang Huang, **Wei Shen**, Senjie Jin, Enyu Zhou, Chenyu Shi, Songyang Gao, Nuo Xu, Yuhao Zhou, Xiaoran Fan, Zhiheng Xi, Jun Zhao, Xiao Wang, Tao Ji, Hang Yan, Lixing Shen, Zhan Chen, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang_

**Human-Instruction-Free LLM Self-Alignment with Limited Samples (Preprint)**

* _Hongyi Guo&#9733;, Yuanshun Yao&#9733;, **Wei Shen**, Jiaheng Wei, Xiaoying Zhang, Zhaoran Wang, Yang Liu_



## 2023 ##

**Mitigating Length Bias in Reinforcement Learning from Human Feedback (EMNLP 2023 Findings)**

* _**Wei Shen**&#9733;, Rui Zheng&#9733;, Wenyu Zhan, Jun Zhao, Shihan Dou, Tao Gui, Qi Zhang, Xuanjing Huang_

**Improving Generalization of Alignment with Human Preferences through Group Invariant Learning (ICLR 2024 Spotlight)**

* _Rui Zheng&#9733;, **Wei Shen**&#9733;, Yuan Hua, Wenbin Lai,  Shihan Dou, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Haoran Huang, Tao Gui, Qi Zhang, Xuanjing Huang_

**Delve into PPO: Implementation Matters for Stable RLHF Training (Instruction Workshop @ NeurIPS 2023 best paper)**
（a.k.a. Secrets of RLHF in Large Language Models Part I: PPO）

* _Rui Zheng&#9733;, Shihan Dou&#9733;, Songyang Gao&#9733;, **Wei Shen**, Binghai Wang, Yan Liu, Senjie Jin, Qin Liu, Yuhao, Zhou, Limao Xiong, Lu Chen, Zhiheng Xi, Nuo Xu, Wenbin Lai, Minghao Zhu, Cheng Chang, Zhangyue Yin, Rongxiang, Weng, Wensen Cheng, Yuan Hua, Haoran Huang, Tianxiang Sun, Hang Yan, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang_




