---
permalink: /
title: "\"In the middle of difficulty lies opportunity.\" _--Albert Einstein_"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## About me

Welcome to my academic page! I am Eric, My Chinese name is Wei Shen (沈蔚), I am excited to share my journey and research endeavors in the field of artificial intelligence.

I completed my bachelor's degree at Huazhong University of Science and Technology (HUST) in 2020. Currently, I am a third-year graduate student at Fudan University, working in the NLP Lab under the guidance of [Xuanjing Huang](https://xuanjing-huang.github.io/) as my advisor, with [Qi Zhang](http://qizhang.info/)  as my co-advisor.

I am passionate about leveraging language models to enhance various aspects of AI and contribute to the development of advanced and responsible AI systems. I am also applying for a Ph.D. in Computer Science, starting in the fall of 2024!

## Research Interests
My research interests primarily revolve around Natural Language Processing (NLP), with a specific focus on LLM alignment, including reward modeling. Additionally, I am eager to explore the realm of LLM agents and contribute to advancements in that area.

## Education
* M.Eng. in Fudan University, NLP Lab, 2021-2024, Shanghai
  <!-- * advisor: [Xuanjing Huang](https://scholar.google.com/citations?user=AnBUn0QAAAAJ&hl=en), and co-advisor [Qi Zhang](http://qizhang.info/) and [Tao Gui](https://guitaowufeng.github.io/) -->
* B.Eng. in Huazhong University of Science and Technology, 2016-2020, Wuhan
* High School in Changjun High School, 2013-2016, Changsha

## Experience

* 2023.8 - present: Research Internship
  * ByteDance AI Lab, Responsible AI team
  * Supervisor: [Liu Yang](http://www.yliuu.com/), Xiaoying Zhang
  * Content: RLHF with imperfect reward model
 
* 2021.9 - 2022.3: Research Internship
  * Fudan CISL Lab
  * Supervisor: [Shang Li](https://scholar.google.com/citations?user=AnBUn0QAAAAJ&hl=en)
      
## News
[2024.1.16] Our paper "Improving Generalization of Alignment with Human Preferences through Group Invariant Learning" has been accepted for **spotlight**(5%) on ICLR 2024!

[2023.12.15] Our paper "Delve into PPO: Implementation Matters for Stable RLHF" has won the Best Paper on Instruction Workshop @ NeurIPS 2023!

## Projects
<img src="../images/moss_logo.png" width="200">

[MOSS-RLHF](https://openlmlab.github.io/MOSS-RLHF/) (An open-source RLHF project aims to help LLMs to achieve alignment easily)


## Publications
### Mitigating Length Bias in Reinforcement Learning from Human Feedback (EMNLP 2023 Findings)

_**Wei Shen**&#9733;, Rui Zheng&#9733;, Wenyu Zhan, Jun Zhao, Shihan Dou, Tao Gui, Qi Zhang, Xuanjing Huang_

### Improving Generalization of Alignment with Human Preferences through Group Invariant Learning (ICLR 2024 Spotlight)

_Rui Zheng*&#9733;, **Wei Shen**&#9733;, Yuan Hua, Wenbin Lai,  Shihan Dou, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Haoran Huang, Tao Gui, Qi Zhang, Xuanjing Huang_

### Delve into PPO: Implementation Matters for Stable RLHF Training (Instruction Workshop @ NeurIPS 2023 best paper)
（a.k.a. Secrets of RLHF in Large Language Models Part I: PPO）

_Rui Zheng&#9733;, Shihan Dou&#9733;, Songyang Gao&#9733;, **Wei Shen**, Binghai Wang, Yan Liu, Senjie Jin, Qin Liu, Yuhao, Zhou, Limao Xiong, Lu Chen, Zhiheng Xi, Nuo Xu, Wenbin Lai, Minghao Zhu, Cheng Chang, Zhangyue Yin, Rongxiang, Weng, Wensen Cheng, Yuan Hua, Haoran Huang, Tianxiang Sun, Hang Yan, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang_


### LoRAMoE: Revolutionizing Mixture of Experts for Maintaining World Knowledge in Language Model Alignment (Preprint)

_Shihan Dou&#9733;, Enyu Zhou&#9733;, Yan Liu, Songyang Gao, Jun Zhao, **Wei Shen**, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Xiaoran Fan, Shiliang Pu, Jiang Zhu, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang_
